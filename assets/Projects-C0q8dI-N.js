import{j as e,m as o}from"./animations-BssLMOIW.js";import{e as p,P as k,O as g,h as l,i as h,j as M,X as G,T as u,D as f,R as T,k as P,l as x,G as D,f as d,m as _,b as I,c as L,C as R,g as z,d as E,n as F}from"./index-Su2eM7C2.js";import{r as n}from"./vendor-DFOSJvNa.js";import"./ui-u3mN8FSn.js";/**
 * @license lucide-react v0.453.0 - ISC
 *
 * This source code is licensed under the ISC license.
 * See the LICENSE file in the root directory of this source tree.
 */const V=p("ChevronUp",[["path",{d:"m18 15-6-6-6 6",key:"153udz"}]]);/**
 * @license lucide-react v0.453.0 - ISC
 *
 * This source code is licensed under the ISC license.
 * See the LICENSE file in the root directory of this source tree.
 */const H=p("ExternalLink",[["path",{d:"M15 3h6v6",key:"1q9fwt"}],["path",{d:"M10 14 21 3",key:"gplh6r"}],["path",{d:"M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6",key:"a6xqqp"}]]);var q="AspectRatio",y=n.forwardRef((t,a)=>{const{ratio:i=1/1,style:r,...c}=t;return e.jsx("div",{style:{position:"relative",width:"100%",paddingBottom:`${100/i}%`},"data-radix-aspect-ratio-wrapper":"",children:e.jsx(k.div,{...c,ref:a,style:{...r,position:"absolute",top:0,right:0,bottom:0,left:0}})})});y.displayName=q;var O=y;const v=O,m=[{title:"Fast Text Based Clustering Strategies",tech:"NLP, Clustering, Jaccard Similarity, K-Means",description:"Comparative analysis of K-Means and custom Jaccard-based clustering algorithms on high-dimensional text data.",longDescription:"This project investigates clustering techniques for text data using the 'Bag of Words' dataset (Enron, NIPS, KOS). It contrasts standard K-Means (Euclidean distance on binary vectors) with custom algorithms optimized for Jaccard Similarity. The custom 'Strategy 2' implements efficient sparse set representations and threshold-based centroid construction, significantly improving performance on the large Enron dataset. Key results include determining optimal cluster counts: KOS (2), NIPS (3), and Enron (4).",github:"https://github.com/sampadk04/CMI_Projects/tree/main/DMML_Assignments/Fast_Text_based_Clustering",date:"April 2022",image:"https://raw.githubusercontent.com/sampadk04/CMI_Projects/main/DMML_Assignments/Fast_Text_based_Clustering/project-asset.png",previewColor:"from-emerald-500/10 to-cyan-500/10"},{title:"Facial Emotion Detector",tech:"Computer Vision, ResNet-18, Transfer Learning, Haar Cascade, Temporal Smoothing, GPU",description:"A real-time facial emotion detection system built from scratch using deep learning with custom ResNet-18 and transfer learning approaches.",longDescription:"A deep learning system that classifies facial expressions into seven emotions: Angry, Disgust, Fear, Happy, Neutral, Sad, and Surprise. Implements both a custom ResNet-18 architecture (55.22% accuracy) and transfer learning with pre-trained ResNet-18 (57.06% accuracy). Features real-time webcam detection using OpenCV's Haar Cascade with temporal smoothing for stable predictions. The system includes GPU-accelerated inference and a complete preprocessing pipeline trained on the Kaggle Facial Expression Dataset.",github:"https://github.com/sampadk04/Facial_Emotion_Detector",date:"January 2023",image:"https://raw.githubusercontent.com/sampadk04/Facial_Emotion_Detector/main/project-asset.png",previewColor:"from-green-500/10 to-emerald-500/10"},{title:"Local GPT for Documents",tech:"NLP, Ollama, Vector Embeddings, LangChain, RAG, ChromaDB, HuggingFace",description:"Privacy-focused local document querying system using Llama2. Query personal documents with natural language while maintaining complete data privacy through on-device processing.",longDescription:"A Retrieval-Augmented Generation (RAG) system for querying personal documents with complete privacy. Built with LangChain and ChromaDB, MyLocalGPT processes PDF, TXT, and CSV files entirely locally using Llama2 models. The system converts documents into vector embeddings for semantic search, then generates context-aware answers with source attribution. Features include conversation memory for multi-turn dialogues, flexible model selection for different hardware (CPU, CUDA, MPS), and configurable embedding options. Ideal for research assistance, legal document analysis, and personal knowledge management without compromising data privacy.",github:"https://github.com/sampadk04/LocalGPT_Projects/tree/main/MyLocalGPT",date:"August 2022",image:"https://raw.githubusercontent.com/sampadk04/LocalGPT_Projects/main/MyLocalGPT/project-asset.png",previewColor:"from-yellow-500/10 to-orange-500/10"},{title:"SSMs: An Efficient Alternative to Attention",tech:"Thesis, NLP, SSMs, Attention",description:"A comprehensive thesis surveying State Space Models (SSMs) as efficient alternatives to Transformers for sequence modeling, with implementations and experiments on text, image, and audio generation.",longDescription:"My Master's thesis from CMI explores State Space Models (SSMs) as efficient alternatives to Transformers for handling long-range dependencies in sequence modeling. The research surveys prominent SSM variants including S4, Mamba, Linear Recurrent Units (LRUs), and Griffin, analyzing their theoretical foundations and empirical performance. SSMs overcome the quadratic complexity of attention mechanisms while maintaining effectiveness on challenging benchmarks like the Long Range Arena, with S4 being the first to solve the difficult PathX task. The thesis includes experimental implementations comparing Transformers and Mamba on character-level language modeling (Tiny Shakespeare), MIDI music generation (Maestro V2), and sequential image generation (MNIST), demonstrating the potential of SSMs for efficient long-context processing in applications like genomics, high-resolution image analysis, and language understanding.",github:"https://github.com/sampadk04/CMI_Masters_Thesis",date:"May 2024",image:"https://raw.githubusercontent.com/sampadk04/CMI_Masters_Thesis/main/project-asset.png",previewColor:"from-red-500/10 to-pink-500/10"},{title:"Attention GAN",tech:"Computer Vision, PyTorch, GANs, Attention Mechanisms, CycleGAN, Image-to-Image Translation",description:"A comprehensive implementation and analysis of Attention-guided GANs for unpaired image-to-image translation, featuring multi-mask attention architectures for superior background preservation.",longDescription:"This project explores and implements the 'Unpaired Image-to-Image Translation using Attention-guided Generative Adversarial Network' paper. It addresses the limitations of traditional GANs like CycleGAN by introducing attention masks that allow the model to focus on semantically important regions (foreground) while preserving the background. The implementation features a dual-scheme architecture, with 'Scheme 2' utilizing multiple attention masks (n=10) and a dedicated content generator for superior semantic localization. Experiments across diverse datasets—including Horse-Zebra, Apple-Orange, and Selfie-Anime—demonstrate that the Attention-guided GAN achieves state-of-the-art performance, significantly reducing artifacts and preserving background details compared to baseline models.",github:"https://github.com/sampadk04/ML_Paper_Codes/tree/main/GANs/Attention_GAN",date:"July 2023",image:"https://raw.githubusercontent.com/sampadk04/ML_Paper_Codes/main/GANs/Attention_GAN/project-asset.png",previewColor:"from-yellow-500/10 to-orange-500/10"},{title:"CNN GANs: Vanilla, DCGAN & CGAN",tech:"Computer Vision, PyTorch, GANs, DCGAN, CGAN, Vanilla GAN, MNIST",description:"Implementation and comparative analysis of three GAN architectures: Vanilla GAN, DCGAN, and Conditional GAN (CGAN) on the MNIST dataset.",longDescription:"A comprehensive implementation and analysis of three Generative Adversarial Network (GAN) architectures trained on the MNIST dataset. The project begins with Vanilla GAN, utilizing fully connected layers to establish a baseline. It advances to DCGAN (Deep Convolutional GAN), which leverages convolutional layers and Batch Normalization for superior image quality and training stability. Finally, CGAN (Conditional GAN) is implemented to introduce controllability, enabling the generation of specific digits via class labels. The study highlights the progression from simple MLPs to sophisticated convolutional models, demonstrating significant improvements in spatial coherence and generation control.",github:"https://github.com/sampadk04/ML_Paper_Codes/tree/main/GANs/CNN_GANs",date:"January 2023",image:"https://raw.githubusercontent.com/sampadk04/ML_Paper_Codes/main/GANs/CNN_GANs/project-asset.png",previewColor:"from-green-500/10 to-emerald-500/10"},{title:"Spotify Themed Website",tech:"React, TypeScript, Tailwind CSS, Framer Motion, Vite, Express.js",description:"A modern, responsive portfolio website with a Spotify-inspired aesthetic, featuring a custom blog system and dynamic project showcasing.",longDescription:"A comprehensive personal portfolio website designed with a Spotify-inspired aesthetic. Built using React and TypeScript for type-safe component architecture, styled with Tailwind CSS for responsive design, and animated with Framer Motion for smooth transitions. Features include a custom file-based blog system, dynamic project showcasing, and a contact form integrated with EmailJS. The backend utilizes Express.js and Drizzle ORM for potential data persistence.",github:"https://github.com/sampadk04/my-spotify-portfolio",date:"November 2023",image:"https://raw.githubusercontent.com/sampadk04/sampadk04.github.io/main/project-asset.png",previewColor:"from-green-500/10 to-emerald-500/10"}],U=T,B=P,b=n.forwardRef(({className:t,...a},i)=>e.jsx(g,{ref:i,className:l("fixed inset-0 z-50 bg-black/80  data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0",t),...a}));b.displayName=g.displayName;const N=n.forwardRef(({className:t,children:a,...i},r)=>e.jsxs(B,{children:[e.jsx(b,{}),e.jsxs(h,{ref:r,className:l("fixed left-[50%] top-[50%] z-50 grid w-full max-w-lg translate-x-[-50%] translate-y-[-50%] gap-4 border bg-background p-6 shadow-lg duration-200 data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[state=closed]:slide-out-to-left-1/2 data-[state=closed]:slide-out-to-top-[48%] data-[state=open]:slide-in-from-left-1/2 data-[state=open]:slide-in-from-top-[48%] sm:rounded-lg max-h-[85vh] overflow-y-auto",t),...i,children:[a,e.jsxs(M,{className:"absolute right-4 top-4 rounded-sm opacity-70 ring-offset-background transition-opacity hover:opacity-100 focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 disabled:pointer-events-none data-[state=open]:bg-accent data-[state=open]:text-muted-foreground",children:[e.jsx(G,{className:"h-4 w-4"}),e.jsx("span",{className:"sr-only",children:"Close"})]})]})]}));N.displayName=h.displayName;const w=({className:t,...a})=>e.jsx("div",{className:l("flex flex-col space-y-1.5 text-center sm:text-left",t),...a});w.displayName="DialogHeader";const j=n.forwardRef(({className:t,...a},i)=>e.jsx(u,{ref:i,className:l("text-lg font-semibold leading-none tracking-tight",t),...a}));j.displayName=u.displayName;const A=n.forwardRef(({className:t,...a},i)=>e.jsx(f,{ref:i,className:l("text-sm text-muted-foreground",t),...a}));A.displayName=f.displayName;function $({project:t,open:a,onOpenChange:i}){return t?e.jsx(U,{open:a,onOpenChange:i,children:e.jsxs(N,{className:"sm:max-w-[700px] border-primary/20 bg-background/95 backdrop-blur-xl",children:[e.jsxs(w,{children:[e.jsx(j,{className:"text-2xl font-bold bg-clip-text text-transparent bg-gradient-to-r from-foreground to-foreground/70",children:t.title}),e.jsxs("div",{className:"flex items-center gap-2 text-sm text-muted-foreground",children:[e.jsx("span",{className:"text-primary font-medium",children:t.tech}),e.jsx("span",{children:"•"}),e.jsx("span",{children:t.date})]})]}),e.jsxs("div",{className:"space-y-6 overflow-y-auto max-h-[70vh] pr-2 custom-scrollbar",children:[e.jsxs(v,{ratio:1/1,className:"overflow-hidden rounded-lg border border-primary/10 shadow-2xl",children:[e.jsx("div",{className:`absolute inset-0 bg-gradient-to-br ${t.previewColor} opacity-20`}),e.jsx("img",{src:t.image,alt:t.title,className:"object-cover w-full h-full transform transition-transform duration-700 hover:scale-105"})]}),e.jsx(A,{className:"text-foreground/90 text-lg leading-relaxed",children:t.longDescription}),e.jsx("div",{className:"flex gap-4 pt-2",children:e.jsx(x,{asChild:!0,className:"group relative overflow-hidden",children:e.jsxs("a",{href:t.github,target:"_blank",rel:"noopener noreferrer",className:"flex items-center gap-2",children:[e.jsx("div",{className:"absolute inset-0 bg-primary/20 translate-y-full group-hover:translate-y-0 transition-transform duration-300"}),e.jsx(D,{className:"w-4 h-4 relative z-10"}),e.jsx("span",{className:"relative z-10",children:"View on GitHub"})]})})})]})]})}):null}function Q(){const[t,a]=n.useState(null),[i,r]=n.useState(!1),c=i?m:m.slice(0,6),C=()=>{r(s=>!s)};return e.jsxs("section",{id:"projects",className:"py-20 bg-background",children:[e.jsxs("div",{className:"container px-4 md:px-6",children:[e.jsx(o.h2,{className:"text-3xl font-bold mb-12 text-center",initial:"initial",whileInView:"animate",viewport:{once:!0},variants:d,children:"Featured Projects"}),e.jsx(o.div,{className:"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6 md:gap-8",variants:i?_:I,initial:"initial",whileInView:"animate",viewport:{once:!0,margin:"-50px"},children:c.map((s,S)=>e.jsx(o.div,{variants:d,className:"group",children:e.jsx(o.div,{initial:"rest",whileHover:"hover",variants:L,className:"h-full",children:e.jsxs(R,{className:"h-full cursor-pointer overflow-hidden border-primary/10 bg-background/40 backdrop-blur-md hover:border-primary/30 hover:shadow-2xl hover:shadow-primary/5 transition-all duration-500",onClick:()=>a(s),children:[e.jsxs("div",{className:"relative overflow-hidden",children:[e.jsxs(v,{ratio:1/1,children:[e.jsx("div",{className:`absolute inset-0 bg-gradient-to-br ${s.previewColor} opacity-20 z-10`}),e.jsx("img",{src:s.image,alt:s.title,className:"object-cover w-full h-full transition-transform duration-700 group-hover:scale-110",loading:"lazy"})]}),e.jsx("div",{className:"absolute inset-0 bg-black/60 opacity-0 group-hover:opacity-100 transition-opacity duration-300 flex items-center justify-center z-20 backdrop-blur-[2px]",children:e.jsx("span",{className:"text-white font-medium px-6 py-2 rounded-full border border-white/20 bg-white/10 backdrop-blur-md transform translate-y-4 group-hover:translate-y-0 transition-transform duration-300",children:"View Details"})})]}),e.jsxs(z,{className:"p-6 pb-2 space-y-2",children:[e.jsxs("div",{className:"flex justify-between items-start gap-4",children:[e.jsx("h3",{className:"text-xl font-bold leading-tight group-hover:text-primary transition-colors duration-300 line-clamp-2",children:s.title}),e.jsx(H,{className:"w-5 h-5 text-muted-foreground/50 group-hover:text-primary transition-colors duration-300 flex-shrink-0"})]}),e.jsx("p",{className:"text-sm font-medium text-primary/80",children:s.tech})]}),e.jsx(E,{className:"p-6 pt-2",children:e.jsx("p",{className:"text-muted-foreground text-sm leading-relaxed line-clamp-3",children:s.description})})]})})},`${s.title}-${S}`))},`projects-${c.length}`),m.length>6&&e.jsx(o.div,{className:"mt-16 flex justify-center",initial:"initial",whileInView:"animate",viewport:{once:!0},variants:d,children:e.jsx(x,{variant:"outline",size:"lg",className:"group min-w-[200px] border-primary/20 hover:border-primary/50 hover:bg-primary/5 transition-all duration-300",onClick:C,children:i?e.jsxs("span",{className:"flex items-center gap-2",children:["Show Less ",e.jsx(V,{className:"w-4 h-4 transition-transform duration-300 group-hover:-translate-y-1"})]}):e.jsxs("span",{className:"flex items-center gap-2",children:["Show More ",e.jsx(F,{className:"w-4 h-4 transition-transform duration-300 group-hover:translate-y-1"})]})})})]}),e.jsx($,{project:t,open:t!==null,onOpenChange:s=>!s&&a(null)})]})}export{Q as default};
